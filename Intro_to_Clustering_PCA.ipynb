{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is clustering?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsupervised algorithm in machine learning aimed at finding out natural groups within existing dataset, without foreknowlegde of the output variable. It is a useful exploratory exercise to understand if muliple approaches might be required going into the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lloyd's algorithm is commonly used with the basic principle of\n",
    "1. Minimize the within cluster distance (different distance measures could be used)\n",
    "2. Maximize the distance between clusters. \n",
    "\n",
    "K-means clustering has drawbacks \n",
    "1. The number of clusters k is an input parameter: an inappropriate choice of k may yield poor results. \n",
    "2. When performing k-means, it is important to run diagnostic checks for determining the number of clusters in the data set.\n",
    "3. Convergence to a local minimum may produce erroneous. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![KMeansUrl](https://upload.wikimedia.org/wikipedia/commons/e/ea/K-means_convergence.gif \"k-means\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By Chire - Own work, CC BY-SA 4.0, https://commons.wikimedia.org/w/index.php?curid=59409335"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 - a random assignation of cluster means. \n",
    "Step 2 - calculate distance of each point from all cluster means, and assign to closest cluster. \n",
    "Step 3 - Calculate mean of all points in the new cluster. \n",
    "Step 4 - repeat step 2 for new mean points. \n",
    "\n",
    "Iteratively a mean is assigned and the algorithm is run to arrive at the right cluster, took about 14 iterations in this case for the animation on top. It can be observed that the movement starts to become less and less and eventually stabilized."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is PCA (Principal Component Analyses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a high (n) dimensional space with potentially correlated features, PCA helps to reduce dimensions (k (< n) orthogonal) to minimize information loss. Typically, first couple of principle components are used in bi-plot to show the variation in a 2D space. ~90% variation should ideally be captured by the PCs. this is shown in 2 dimensional space example below.   \n",
    "\n",
    "For 2 dimensional case, PCA is akin to co-ordinate transformation alone, which can be seen with the arrows in the middle of the plot. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, SVG, Math, YouTubeVideo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/f5/GaussianScatterPCA.svg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url = 'https://upload.wikimedia.org/wikipedia/commons/f/f5/GaussianScatterPCA.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nicoguaro [CC BY 4.0 (https://creativecommons.org/licenses/by/4.0)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the dimension space starts to grow, representation becomes less intuitive. It is also recommended to check this URL for an interactive version - http://setosa.io/ev/principal-component-analysis/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limitations of PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Results depend on the scaling of the variables. \n",
    "2. Can capture linear correlation but not more. \n",
    "3. Interpreting abstractions can be demanding. \n",
    "\n",
    "It does require scaling/normalization with standard deviation, which has been used in this case. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation to k-means clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cluster centroid subspace and PCA subspace are related to each other in a loose mathematical fashion and both can be interchangeably used. \n",
    "\n",
    "Reference : http://ranger.uta.edu/~chqding/papers/KmeansPCA1.pdf\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
